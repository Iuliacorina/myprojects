{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydHb_ZL5yy6f"
      },
      "source": [
        "# **Final Project Task 3 - Census Modeling Regression**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnzXS8Oo9jwY"
      },
      "source": [
        "Requirements\n",
        "\n",
        "- You can use models (estmators) from sklearn, but feel free to use any library for traditional ML. \n",
        "    - Note: in sklearn, the LinearRegression estimator is based on OLS, a statistical method. Please use the SGDRegressor estimator, since this is based on gradient descent. \n",
        "    - You can use LinearRegression estimator, but only as comparison with the SGDRegressor - Optional.\n",
        "\n",
        "- Model Selection and Setup:\n",
        "    - Implement multiple models, to solve a regression problem using traditional ML:\n",
        "        - Linear Regression\n",
        "        - Decision Tree Regression\n",
        "        - Random Forest Regression - Optional\n",
        "        - Ridge Regression - Optional\n",
        "        - Lasso Regression - Optional\n",
        "    - Choose a loss (or experiment with different losses) for the model and justify the choice.\n",
        "        - MSE, MAE, RMSE, Huber Loss or others\n",
        "    - Justify model choices based on dataset characteristics and task requirements; specify model pros and cons.\n",
        "\n",
        "\n",
        "- Data Preparation\n",
        "    - Use the preprocessed datasets from Task 1.\n",
        "    - From the train set, create an extra validation set, if necesarry. So in total there will be: train, validation and test datasets.\n",
        "    - Be sure all models have their data preprocessed as needed. Some models require different, or no encoding for some features.\n",
        "\n",
        "\n",
        "- Model Training and Experimentation\n",
        "    - Establish a Baseline Model:\n",
        "        - For each model type, train a simple model with default settings as a baseline.\n",
        "        - Evaluate its performance to establish a benchmark for comparison.\n",
        "    - Make plots with train, validation loss and metric on epochs (or on steps), if applicable. - Optional\n",
        "    - Feature Selection:\n",
        "        - Use insights from EDA in Task 2 to identify candidate features by analyzing patterns, relationships, and distributions.\n",
        "    - Experimentation:\n",
        "        - For each baseline model type, iteratively experiment with different combinations of features and transformations.\n",
        "        - Experiment with feature engineering techniques such as interaction terms, polynomial features, or scaling transformations.\n",
        "        - Identify the best model which have the best performance metrics on test set.\n",
        "    - Hyperparameter Tuning:\n",
        "        - Perform hyperparameter tuning only on the best-performing model after evaluating all model types and experiments.\n",
        "        - Avoid tuning models that do not show strong baseline performance or are unlikely to outperform others based on experimentation.\n",
        "        - Ensure that hyperparameter tuning is done after completing feature selection, baseline modeling, and experimentation, ensuring that the model is stable and representative of the dataset.\n",
        "\n",
        "\n",
        "- Model Evaluation\n",
        "    - Evaluate models on the test dataset using regression metrics:\n",
        "        - Mean Absolute Error (MAE)\n",
        "        - Mean Squared Error (MSE)\n",
        "        - Root Mean Squared Error (RMSE)\n",
        "        - RÂ² Score\n",
        "    - Compare the results across different models. Save all experiment results into a table.\n",
        "\n",
        "Feature Importance - Optional\n",
        "- For applicable models (e.g., Decision Tree Regression), analyze feature importance and discuss its relevance to the problem.\n",
        "\n",
        "\n",
        "\n",
        "Deliverables\n",
        "\n",
        "- Notebook code with no errors.\n",
        "- Code and results from experiments. Create a table with all experiments results, include experiment name, metrics results.\n",
        "- Explain findings, choices, results.\n",
        "- Potential areas for improvement or further exploration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, OneHotEncoder\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression, SGDRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "CzWyJfHkyn-8",
        "outputId": "633344dd-56a2-44a7-a237-a26873898c80"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "      <th>income</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22791</th>\n",
              "      <td>39</td>\n",
              "      <td>Self-emp-inc</td>\n",
              "      <td>372525</td>\n",
              "      <td>Masters</td>\n",
              "      <td>14</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10185</th>\n",
              "      <td>48</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>164582</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Farming-fishing</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>7298</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25298</th>\n",
              "      <td>41</td>\n",
              "      <td>Self-emp-not-inc</td>\n",
              "      <td>97277</td>\n",
              "      <td>Assoc-voc</td>\n",
              "      <td>11</td>\n",
              "      <td>Divorced</td>\n",
              "      <td>Other-service</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5372</th>\n",
              "      <td>27</td>\n",
              "      <td>Private</td>\n",
              "      <td>36851</td>\n",
              "      <td>Assoc-voc</td>\n",
              "      <td>11</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Sales</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>35</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10345</th>\n",
              "      <td>28</td>\n",
              "      <td>Private</td>\n",
              "      <td>261725</td>\n",
              "      <td>1st-4th</td>\n",
              "      <td>2</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>Mexico</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11658</th>\n",
              "      <td>19</td>\n",
              "      <td>?</td>\n",
              "      <td>318264</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>?</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4441</th>\n",
              "      <td>43</td>\n",
              "      <td>Self-emp-inc</td>\n",
              "      <td>286750</td>\n",
              "      <td>Prof-school</td>\n",
              "      <td>15</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Prof-specialty</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>99</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&gt;50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7324</th>\n",
              "      <td>58</td>\n",
              "      <td>Private</td>\n",
              "      <td>175127</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>United-States</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19787</th>\n",
              "      <td>29</td>\n",
              "      <td>Private</td>\n",
              "      <td>46609</td>\n",
              "      <td>10th</td>\n",
              "      <td>6</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Craft-repair</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>40</td>\n",
              "      <td>?</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8466</th>\n",
              "      <td>25</td>\n",
              "      <td>Private</td>\n",
              "      <td>359985</td>\n",
              "      <td>5th-6th</td>\n",
              "      <td>3</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Not-in-family</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>33</td>\n",
              "      <td>Mexico</td>\n",
              "      <td>&lt;=50K</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       age         workclass  fnlwgt     education  education-num  \\\n",
              "22791   39      Self-emp-inc  372525       Masters             14   \n",
              "10185   48  Self-emp-not-inc  164582  Some-college             10   \n",
              "25298   41  Self-emp-not-inc   97277     Assoc-voc             11   \n",
              "5372    27           Private   36851     Assoc-voc             11   \n",
              "10345   28           Private  261725       1st-4th              2   \n",
              "11658   19                 ?  318264  Some-college             10   \n",
              "4441    43      Self-emp-inc  286750   Prof-school             15   \n",
              "7324    58           Private  175127       HS-grad              9   \n",
              "19787   29           Private   46609          10th              6   \n",
              "8466    25           Private  359985       5th-6th              3   \n",
              "\n",
              "           marital-status         occupation   relationship   race     sex  \\\n",
              "22791  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
              "10185  Married-civ-spouse    Farming-fishing        Husband  White    Male   \n",
              "25298            Divorced      Other-service      Unmarried  White  Female   \n",
              "5372   Married-civ-spouse              Sales        Husband  White    Male   \n",
              "10345       Never-married  Machine-op-inspct  Not-in-family  White  Female   \n",
              "11658       Never-married                  ?      Own-child  White    Male   \n",
              "4441   Married-civ-spouse     Prof-specialty        Husband  Black    Male   \n",
              "7324   Married-civ-spouse  Machine-op-inspct        Husband  White    Male   \n",
              "19787       Never-married       Craft-repair  Not-in-family  Black    Male   \n",
              "8466        Never-married       Adm-clerical  Not-in-family  White  Female   \n",
              "\n",
              "       capital-gain  capital-loss  hours-per-week native-country income  \n",
              "22791             0             0              60  United-States   >50K  \n",
              "10185          7298             0              60  United-States   >50K  \n",
              "25298             0             0              10  United-States  <=50K  \n",
              "5372              0             0              35  United-States  <=50K  \n",
              "10345             0             0              40         Mexico  <=50K  \n",
              "11658             0             0              30  United-States  <=50K  \n",
              "4441              0             0              99  United-States   >50K  \n",
              "7324              0             0              40  United-States  <=50K  \n",
              "19787             0             0              40              ?  <=50K  \n",
              "8466              0             0              33         Mexico  <=50K  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
        "#columns = [\n",
        "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\",\n",
        "    \"occupation\", \"relationship\", \"race\", \"sex\", \"capital-gain\", \"capital-loss\",\n",
        "    \"hours-per-week\", \"native-country\", \"income\"\n",
        "#]\n",
        "\n",
        "#data = pd.read_csv(data_url, header=None, names=columns, na_values=\" ?\", skipinitialspace=True)\n",
        "#data.sample(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_raw = pd.read_csv(\"train_raw.csv\")\n",
        "test_raw = pd.read_csv(\"test_raw.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = train_raw.copy()\n",
        "test_df = test_raw.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_variable = \"hours-per-week\"\n",
        "\n",
        "# Separating features and target variable \n",
        "x_train = train_raw.drop(columns=[target_variable])\n",
        "y_train = train_raw[target_variable]\n",
        "\n",
        "x_test = test_raw.drop(columns=[target_variable])\n",
        "y_test = test_raw[target_variable]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split train set into train and validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df, val_df = train_test_split(train_raw, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preprocess transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "# applying standardization, normalization and scaling on train, test and validation set\n",
        "def standardization_transform(train_df, test_df, val_df, columns):\n",
        "    _train_df = train_df.copy()\n",
        "    _test_df = test_df.copy()\n",
        "    _val_df = val_df.copy()\n",
        "\n",
        "    ss = StandardScaler()\n",
        "    _train_df[columns] = ss.fit_transform(_train_df[columns])\n",
        "    _test_df[columns] = ss.transform(_test_df[columns])\n",
        "    _val_df[columns] = ss.transform(_val_df[columns])\n",
        "\n",
        "    return _train_df, _test_df, _val_df\n",
        "\n",
        "def normalization_transform(train_df, test_df, val_df, columns):\n",
        "    _train_df = train_df.copy()\n",
        "    _test_df = test_df.copy()\n",
        "    _val_df = val_df.copy()\n",
        "\n",
        "    mms = MinMaxScaler()\n",
        "    _train_df[columns] = mms.fit_transform(_train_df[columns])\n",
        "    _test_df[columns] = mms.transform(_test_df[columns])\n",
        "    _val_df[columns] = mms.transform(_val_df[columns])\n",
        "\n",
        "    return _train_df, _test_df, _val_df\n",
        "\n",
        "def scaling_transform(train_df, test_df, val_df, columns):\n",
        "    _train_df = train_df.copy()\n",
        "    _test_df = test_df.copy()\n",
        "    _val_df = val_df.copy()\n",
        "\n",
        "    rs = RobustScaler()\n",
        "    _train_df[columns] = rs.fit_transform(_train_df[columns])\n",
        "    _test_df[columns] = rs.transform(_test_df[columns])\n",
        "    _val_df[columns] = rs.transform(_val_df[columns])\n",
        "\n",
        "    return _train_df, _test_df, _val_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Defining preprocess functions \n",
        "def preprocess1(train_df, test_df, val_df):\n",
        "    s_columns = ['age', 'education-num', 'capital-gain', 'education_simplified', 'sex', 'full_time']\n",
        "    \n",
        "    _train_df, _test_df, _val_df = standardization_transform(train_df, test_df, val_df, s_columns)\n",
        "\n",
        "    all_columns = s_columns + [target_variable]\n",
        "    _train_df = _train_df[all_columns]\n",
        "    _test_df = _test_df[all_columns]\n",
        "    _val_df = _val_df[all_columns]\n",
        "\n",
        "    print(\"Preprocessed train_df (head):\")\n",
        "    print(_train_df.head())\n",
        "\n",
        "    return _train_df, _test_df, _val_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessed train_df (head):\n",
            "            age  education-num  capital-gain  education_simplified       sex  \\\n",
            "13242  0.276354       1.301974     -0.208253              1.642777 -1.260805   \n",
            "16886 -0.691167      -0.326248     -0.208253             -0.344529  0.793144   \n",
            "5     -1.063291      -0.326248     -0.208253             -0.344529  0.793144   \n",
            "2656  -0.542318      -0.326248     -0.208253             -0.344529 -1.260805   \n",
            "13244  1.020602      -0.326248      3.711542             -0.344529  0.793144   \n",
            "\n",
            "       full_time  hours-per-week  \n",
            "13242  -0.165111              25  \n",
            "16886  -0.165111              40  \n",
            "5      -0.165111              40  \n",
            "2656   -0.165111              40  \n",
            "13244  -0.165111              40  \n"
          ]
        }
      ],
      "source": [
        "train_df_p1, test_df_p1, val_df_p1 = preprocess1(train_df, test_df, val_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess2(train_df, test_df, val_df):\n",
        "    s_columns = ['age', 'education-num', 'capital-gain', 'education_simplified', 'sex', 'full_time']\n",
        "    \n",
        "    _train_df, _test_df, _val_df = normalization_transform(train_df, test_df, val_df, s_columns)\n",
        "\n",
        "    all_columns = s_columns + [target_variable]\n",
        "    _train_df = _train_df[all_columns]\n",
        "    _test_df = _test_df[all_columns]\n",
        "    _val_df = _val_df[all_columns]\n",
        "\n",
        "    return _train_df, _test_df, _val_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df_p2, test_df_p2, val_df_p2 = preprocess2(train_df, test_df, val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preprocess3(train_df, test_df, val_df):\n",
        "    s_columns = ['age', 'education-num', 'capital-gain', 'education_simplified', 'sex', 'full_time']\n",
        "    \n",
        "    _train_df, _test_df, _val_df = scaling_transform(train_df, test_df, val_df, s_columns)\n",
        "\n",
        "    all_columns = s_columns + [target_variable]\n",
        "    _train_df = _train_df[all_columns]\n",
        "    _test_df = _test_df[all_columns]\n",
        "    _val_df = _val_df[all_columns]\n",
        "\n",
        "    return _train_df, _test_df, _val_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df_p3, test_df_p3, val_df_p3 = preprocess3(train_df, test_df, val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [],
      "source": [
        "datasets = {\n",
        "    'p1': (train_df_p1, test_df_p1, val_df_p1, 'p1'),\n",
        "    'p2': (train_df_p2, test_df_p2, val_df_p2, 'p2'),\n",
        "    'p3': (train_df_p3, test_df_p3, val_df_p3, 'p3')\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regression Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "exp1: linear_regression_ols -> MAE: 5.1142, RÂ²: 0.0688\n",
            "exp2: linear_regression_ols -> MAE: 5.1142, RÂ²: 0.0688\n",
            "exp3: linear_regression_ols -> MAE: 5.1142, RÂ²: 0.0688\n",
            "exp4: linear_regression_sgd -> MAE: 5.1133, RÂ²: 0.0688\n",
            "exp5: linear_regression_sgd -> MAE: 5.1144, RÂ²: 0.0686\n",
            "exp6: linear_regression_sgd -> MAE: 380464548964.1384, RÂ²: -57624107197348121149440.0000\n",
            "exp7: decision_tree -> MAE: 4.4652, RÂ²: 0.1037\n",
            "exp8: decision_tree -> MAE: 4.4624, RÂ²: 0.1035\n",
            "exp9: decision_tree -> MAE: 4.4624, RÂ²: 0.1040\n",
            "exp10: random_forest -> MAE: 4.4224, RÂ²: 0.1560\n",
            "exp11: random_forest -> MAE: 4.4216, RÂ²: 0.1561\n",
            "exp12: random_forest -> MAE: 4.4198, RÂ²: 0.1567\n"
          ]
        }
      ],
      "source": [
        "def get_models(name):\n",
        "    models = {\n",
        "        'linear_regression_ols': LinearRegression,\n",
        "        'linear_regression_sgd': lambda **kwargs: SGDRegressor(random_state=42, max_iter=1000, tol=1e-3, learning_rate='adaptive', eta0=0.001, penalty='l2', **kwargs),\n",
        "        'decision_tree': lambda **kwargs: DecisionTreeRegressor(random_state=42, **kwargs),\n",
        "        'random_forest': lambda **kwargs: RandomForestRegressor(random_state=42, **kwargs)\n",
        "    }\n",
        "    if name not in models:\n",
        "        raise ValueError(f\"Model name '{name}' does not exist!\")\n",
        "    return models[name]\n",
        "\n",
        "# ðŸ”¹ Preprocessed data sets\n",
        "datasets = {\n",
        "    'p1': (train_df_p1, test_df_p1, val_df_p1),  \n",
        "    'p2': (train_df_p2, test_df_p2, val_df_p2),  \n",
        "    'p3': (train_df_p3, test_df_p3, val_df_p3)   \n",
        "}\n",
        "# ðŸ”¹ Define experiments\n",
        "experiments = [\n",
        "    {'name': 'exp1', 'model_name': 'linear_regression_ols', 'dataset': 'p1', 'kwargs': {}},\n",
        "    {'name': 'exp2', 'model_name': 'linear_regression_ols', 'dataset': 'p2', 'kwargs': {}},\n",
        "    {'name': 'exp3', 'model_name': 'linear_regression_ols', 'dataset': 'p3', 'kwargs': {}},\n",
        "    \n",
        "    {'name': 'exp4', 'model_name': 'linear_regression_sgd', 'dataset': 'p1', 'kwargs': {}},\n",
        "    {'name': 'exp5', 'model_name': 'linear_regression_sgd', 'dataset': 'p2', 'kwargs': {}},\n",
        "    {'name': 'exp6', 'model_name': 'linear_regression_sgd', 'dataset': 'p3', 'kwargs': {}},\n",
        "\n",
        "    {'name': 'exp7', 'model_name': 'decision_tree', 'dataset': 'p1', 'kwargs': {}},\n",
        "    {'name': 'exp8', 'model_name': 'decision_tree', 'dataset': 'p2', 'kwargs': {}},\n",
        "    {'name': 'exp9', 'model_name': 'decision_tree', 'dataset': 'p3', 'kwargs': {}},\n",
        "\n",
        "    {'name': 'exp10', 'model_name': 'random_forest', 'dataset': 'p1', 'kwargs': {}},\n",
        "    {'name': 'exp11', 'model_name': 'random_forest', 'dataset': 'p2', 'kwargs': {}},\n",
        "    {'name': 'exp12', 'model_name': 'random_forest', 'dataset': 'p3', 'kwargs': {}}\n",
        "]\n",
        "\n",
        "# ðŸ”¹ Running experiments\n",
        "for experiment in experiments:\n",
        "    exp_name = experiment['name']\n",
        "    model_name = experiment['model_name']\n",
        "    dataset_key = experiment['dataset']\n",
        "    model_kwargs = experiment['kwargs']\n",
        "\n",
        "    train_df, test_df, val_df = datasets[dataset_key]\n",
        "\n",
        "    X_train = train_df.drop(columns=['hours-per-week']).values\n",
        "    y_train = train_df['hours-per-week'].values\n",
        "    X_val = val_df.drop(columns=['hours-per-week']).values\n",
        "    y_val = val_df['hours-per-week'].values\n",
        "    X_test = test_df.drop(columns=['hours-per-week']).values\n",
        "    y_test = test_df['hours-per-week'].values\n",
        "\n",
        "    # Model initialization and training\n",
        "    model_class = get_models(model_name)\n",
        "    model = model_class(**model_kwargs)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Performance metrics calculation: am ales mean absolute error pt ca avem destul de multi outlieri (peste 5000), iar mae este singura care nu este sensibila la outlieri la fel ca mse sau rmse\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "    print(f\"{exp_name}: {model_name} -> MAE: {mae:.4f}, RÂ²: {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Iulia\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
            "5 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\Iulia\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"c:\\Users\\Iulia\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
            "  File \"c:\\Users\\Iulia\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
            "        self._parameter_constraints,\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "        self.get_params(deep=False),\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "        caller_name=self.__class__.__name__,\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    )\n",
            "    ^\n",
            "  File \"c:\\Users\\Iulia\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "    ...<2 lines>...\n",
            "    )\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "c:\\Users\\Iulia\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [-4.40084444 -4.34751958 -4.34682154 -4.35066086 -4.33997343 -4.35651786\n",
            " -4.38340169 -4.34920791         nan -4.36940642]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best hyperparameters: {'min_samples_split': np.int64(12), 'min_samples_leaf': np.int64(1), 'max_features': None, 'max_depth': 10}\n",
            "Best score: 4.3399734277814375\n",
            "Validation MAE: 4.4590, Validation RÂ²: 0.2372\n",
            "Test MAE: 4.3501, Test RÂ²: 0.2212\n",
            "Best Random Forest Model: RandomForestRegressor(max_depth=10, max_features=None,\n",
            "                      min_samples_leaf=np.int64(1),\n",
            "                      min_samples_split=np.int64(12), random_state=42)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['best_random_forest_model.pkl']"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import joblib\n",
        "\n",
        "#Defining parameters\n",
        "param_dist = { \n",
        "    'max_depth': [None, 5, 10, 20], \n",
        "    'min_samples_split': np.arange(2, 20),  \n",
        "    'min_samples_leaf': np.arange(1, 20),  \n",
        "    'max_features': ['auto', 'sqrt', 'log2', None],    \n",
        "}\n",
        "\n",
        "# Create a RandomizedSearchCV object\n",
        "random_search = RandomizedSearchCV(\n",
        "    RandomForestRegressor(random_state=42),\n",
        "    param_distributions=param_dist, \n",
        "    n_iter=10,  \n",
        "    cv=5, \n",
        "    scoring='neg_mean_absolute_error', \n",
        "    random_state=42,\n",
        "    n_jobs=-1  \n",
        ")\n",
        "\n",
        "# Perform the random search\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print the best hyperparameters and score\n",
        "\n",
        "print(\"Best hyperparameters:\", random_search.best_params_)\n",
        "print(\"Best score:\", -random_search.best_score_)\n",
        "\n",
        "# Evaluarea pe setul de validare\n",
        "best_model = random_search.best_estimator_\n",
        "y_val_pred = best_model.predict(X_val)\n",
        "mae_val = mean_absolute_error(y_val, y_val_pred)\n",
        "r2_val = r2_score(y_val, y_val_pred)\n",
        "print(f\"Validation MAE: {mae_val:.4f}, Validation RÂ²: {r2_val:.4f}\")\n",
        "\n",
        "\n",
        "# Evaluarea finalÄƒ pe test\n",
        "y_test_pred = best_model.predict(X_test)\n",
        "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
        "r2_test = r2_score(y_test, y_test_pred)\n",
        "print(f\"Test MAE: {mae_test:.4f}, Test RÂ²: {r2_test:.4f}\")\n",
        "\n",
        "# Get the best model\n",
        "best_rf_model = random_search.best_estimator_\n",
        "# Print the best model \n",
        "print(\"Best Random Forest Model:\", best_rf_model)\n",
        "joblib.dump(best_rf_model, 'best_random_forest_model.pkl')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interpretation of tuning model\n",
        "- Best score: 4.3399734277814375  -- This represents the negative Mean Absolute Error (MAE) value obtained from RandomizedSearchCV. Although it is expressed as a negative value (because RandomizedSearchCV maximizes the score, and MAE is a value to be minimized), the absolute value shows that the MAE is approximately 4.33 on the train data. \n",
        "- Validation MAE: 4.4590 -- This represents the MAE value on the validation set, which means that the model makes an error of about 4.45 units in its predictions.\n",
        "- Validation RÂ²: 0.2372 -- This value represents the value of the coefficient of determination on the validation set. Such a value indicates that 23% of the variation in the target variable (hours-per-week) is explained by the variation in the feature variables included in the model. \n",
        "- On the other hand, the prediction on the other model is similar (22% of the variance of the target variable) and the mean absolute error is also very similar. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Regression Models - Report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tabulate in c:\\users\\iulia\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.9.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: jinja2 in c:\\users\\iulia\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.1.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\iulia\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2) (3.0.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 25.0.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "%pip install tabulate\n",
        "%pip install jinja2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Models Overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_e191f_row12_col0, #T_e191f_row12_col1, #T_e191f_row12_col2, #T_e191f_row12_col3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_e191f\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_e191f_level0_col0\" class=\"col_heading level0 col0\" >Experiment</th>\n",
              "      <th id=\"T_e191f_level0_col1\" class=\"col_heading level0 col1\" >Model</th>\n",
              "      <th id=\"T_e191f_level0_col2\" class=\"col_heading level0 col2\" >Test MAE</th>\n",
              "      <th id=\"T_e191f_level0_col3\" class=\"col_heading level0 col3\" >Test RÂ²</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_e191f_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_e191f_row0_col0\" class=\"data row0 col0\" >exp1</td>\n",
              "      <td id=\"T_e191f_row0_col1\" class=\"data row0 col1\" >linear_regression_ols</td>\n",
              "      <td id=\"T_e191f_row0_col2\" class=\"data row0 col2\" >5.114200</td>\n",
              "      <td id=\"T_e191f_row0_col3\" class=\"data row0 col3\" >0.068800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e191f_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_e191f_row1_col0\" class=\"data row1 col0\" >exp2</td>\n",
              "      <td id=\"T_e191f_row1_col1\" class=\"data row1 col1\" >linear_regression_ols</td>\n",
              "      <td id=\"T_e191f_row1_col2\" class=\"data row1 col2\" >5.114200</td>\n",
              "      <td id=\"T_e191f_row1_col3\" class=\"data row1 col3\" >0.068800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e191f_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_e191f_row2_col0\" class=\"data row2 col0\" >exp3</td>\n",
              "      <td id=\"T_e191f_row2_col1\" class=\"data row2 col1\" >linear_regression_ols</td>\n",
              "      <td id=\"T_e191f_row2_col2\" class=\"data row2 col2\" >5.114200</td>\n",
              "      <td id=\"T_e191f_row2_col3\" class=\"data row2 col3\" >0.068800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e191f_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "      <td id=\"T_e191f_row3_col0\" class=\"data row3 col0\" >exp4</td>\n",
              "      <td id=\"T_e191f_row3_col1\" class=\"data row3 col1\" >linear_regression_sgd</td>\n",
              "      <td id=\"T_e191f_row3_col2\" class=\"data row3 col2\" >5.113300</td>\n",
              "      <td id=\"T_e191f_row3_col3\" class=\"data row3 col3\" >0.068800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e191f_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "      <td id=\"T_e191f_row4_col0\" class=\"data row4 col0\" >exp5</td>\n",
              "      <td id=\"T_e191f_row4_col1\" class=\"data row4 col1\" >linear_regression_sgd</td>\n",
              "      <td id=\"T_e191f_row4_col2\" class=\"data row4 col2\" >5.114400</td>\n",
              "      <td id=\"T_e191f_row4_col3\" class=\"data row4 col3\" >0.068600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e191f_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
              "      <td id=\"T_e191f_row5_col0\" class=\"data row5 col0\" >exp6</td>\n",
              "      <td id=\"T_e191f_row5_col1\" class=\"data row5 col1\" >linear_regression_sgd</td>\n",
              "      <td id=\"T_e191f_row5_col2\" class=\"data row5 col2\" >380464548964.138428</td>\n",
              "      <td id=\"T_e191f_row5_col3\" class=\"data row5 col3\" >-57624107197348121149440.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e191f_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
              "      <td id=\"T_e191f_row6_col0\" class=\"data row6 col0\" >exp7</td>\n",
              "      <td id=\"T_e191f_row6_col1\" class=\"data row6 col1\" >decision_tree</td>\n",
              "      <td id=\"T_e191f_row6_col2\" class=\"data row6 col2\" >4.465200</td>\n",
              "      <td id=\"T_e191f_row6_col3\" class=\"data row6 col3\" >0.103700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e191f_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
              "      <td id=\"T_e191f_row7_col0\" class=\"data row7 col0\" >exp8</td>\n",
              "      <td id=\"T_e191f_row7_col1\" class=\"data row7 col1\" >decision_tree</td>\n",
              "      <td id=\"T_e191f_row7_col2\" class=\"data row7 col2\" >4.462400</td>\n",
              "      <td id=\"T_e191f_row7_col3\" class=\"data row7 col3\" >0.103500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e191f_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
              "      <td id=\"T_e191f_row8_col0\" class=\"data row8 col0\" >exp9</td>\n",
              "      <td id=\"T_e191f_row8_col1\" class=\"data row8 col1\" >decision_tree</td>\n",
              "      <td id=\"T_e191f_row8_col2\" class=\"data row8 col2\" >4.462400</td>\n",
              "      <td id=\"T_e191f_row8_col3\" class=\"data row8 col3\" >0.104000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e191f_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
              "      <td id=\"T_e191f_row9_col0\" class=\"data row9 col0\" >exp10</td>\n",
              "      <td id=\"T_e191f_row9_col1\" class=\"data row9 col1\" >random_forest</td>\n",
              "      <td id=\"T_e191f_row9_col2\" class=\"data row9 col2\" >4.422400</td>\n",
              "      <td id=\"T_e191f_row9_col3\" class=\"data row9 col3\" >0.156000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e191f_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
              "      <td id=\"T_e191f_row10_col0\" class=\"data row10 col0\" >exp11</td>\n",
              "      <td id=\"T_e191f_row10_col1\" class=\"data row10 col1\" >random_forest</td>\n",
              "      <td id=\"T_e191f_row10_col2\" class=\"data row10 col2\" >4.421600</td>\n",
              "      <td id=\"T_e191f_row10_col3\" class=\"data row10 col3\" >0.156100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e191f_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
              "      <td id=\"T_e191f_row11_col0\" class=\"data row11 col0\" >exp12</td>\n",
              "      <td id=\"T_e191f_row11_col1\" class=\"data row11 col1\" >random_forest</td>\n",
              "      <td id=\"T_e191f_row11_col2\" class=\"data row11 col2\" >4.419800</td>\n",
              "      <td id=\"T_e191f_row11_col3\" class=\"data row11 col3\" >0.156700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_e191f_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
              "      <td id=\"T_e191f_row12_col0\" class=\"data row12 col0\" >exp13</td>\n",
              "      <td id=\"T_e191f_row12_col1\" class=\"data row12 col1\" >random_forest_tuned</td>\n",
              "      <td id=\"T_e191f_row12_col2\" class=\"data row12 col2\" >4.350100</td>\n",
              "      <td id=\"T_e191f_row12_col3\" class=\"data row12 col3\" >0.221200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x20656157ed0>"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tabulate import tabulate\n",
        "from jinja2 import Template \n",
        "\n",
        "# Results list\n",
        "results = [\n",
        "    {'Experiment': 'exp1', 'Model': 'linear_regression_ols', 'Test MAE': 5.1142, 'Test RÂ²': 0.0688},\n",
        "    {'Experiment': 'exp2', 'Model': 'linear_regression_ols', 'Test MAE': 5.1142, 'Test RÂ²': 0.0688},\n",
        "    {'Experiment': 'exp3', 'Model': 'linear_regression_ols', 'Test MAE': 5.1142, 'Test RÂ²': 0.0688},\n",
        "    {'Experiment': 'exp4', 'Model': 'linear_regression_sgd', 'Test MAE': 5.1133, 'Test RÂ²': 0.0688},\n",
        "    {'Experiment': 'exp5', 'Model': 'linear_regression_sgd', 'Test MAE': 5.1144, 'Test RÂ²': 0.0686},\n",
        "    {'Experiment': 'exp6', 'Model': 'linear_regression_sgd', 'Test MAE': 380464548964.1384, 'Test RÂ²': -57624107197348121149440.0000},\n",
        "    {'Experiment': 'exp7', 'Model': 'decision_tree', 'Test MAE': 4.4652, 'Test RÂ²': 0.1037},\n",
        "    {'Experiment': 'exp8', 'Model': 'decision_tree', 'Test MAE': 4.4624, 'Test RÂ²': 0.1035},\n",
        "    {'Experiment': 'exp9', 'Model': 'decision_tree', 'Test MAE': 4.4624, 'Test RÂ²': 0.1040},\n",
        "    {'Experiment': 'exp10', 'Model': 'random_forest', 'Test MAE': 4.4224, 'Test RÂ²': 0.1560},\n",
        "    {'Experiment': 'exp11', 'Model': 'random_forest', 'Test MAE': 4.4216, 'Test RÂ²': 0.1561},\n",
        "    {'Experiment': 'exp12', 'Model': 'random_forest', 'Test MAE': 4.4198, 'Test RÂ²': 0.1567},\n",
        "    {'Experiment': 'exp13', 'Model': 'random_forest_tuned', 'Test MAE': 4.3501, 'Test RÂ²': 0.2212}\n",
        "]\n",
        "\n",
        "\n",
        "# DataFrame with list of results\n",
        "import pandas as pd\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Best R2 on test set\n",
        "best_r2 = results_df['Test RÂ²'].max()\n",
        "\n",
        "def highlight_best_model(row):\n",
        "    if row['Test RÂ²'] == best_r2:\n",
        "        return ['font-weight: bold']*len(row) \n",
        "    return ['']*len(row)\n",
        "\n",
        "# Styling\n",
        "styled_df = results_df.style.apply(highlight_best_model, axis=1)\n",
        "\n",
        "styled_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Results:\n",
        "- Among all the 12 models realized, Random Forest seems to perform the best compared to the other models. Having the lowest error values (MAE Test) and the highest RÂ² scores (RÂ² Test), it is clear that this model provides the best prediction on the test set. Among the 3 random forest models, the experiment on the third data set performs the best (Test MAE:4.419800, RÂ²:0.156700). However, the tuned random forest model is the best performer, with the smallest mean absolute error (4.350100) and the highest R2 value (0.221200). \n",
        "- If we were to evaluate the performance of the realized regression models, at the top remains random forest, followed by decision tree and linear regression. Regarding the difference between ols-based linear regression and sgd, ols seems to perform very slightly better, as it has the smaller errors.  \n",
        "- An important mention: the huge amount of values for experiment 6 may be due to the way the third data set was processed, which was not standardized or normalized"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Justification of the regression model used\n",
        "1. Linear regression (OLS)\n",
        "    - I chose linear regression as a starting point in understanding the data sets, because it provides coefficients that easily explain the model prediction and the effects of the explratory variables on the target variable.\n",
        "\n",
        "2. Linear regression (SGD)\n",
        "    - I chose logistic regression with SGD to use a more refined modeling approach, which could be more efficient on larger datasets and more exploratory variables.\n",
        "\n",
        "3. Decision Tree\n",
        "    - I also chose to use decision tree because it is able to learn complex, non-linear relationships between the target variable and the exploratory variables.\n",
        "\n",
        "4. Random Forest\n",
        "    - I also used Random Forest because it combines multiple decision trees to improve model performance and reduce the risk of overfitting. The model also handles complex data better and generalizes better on unknown sets. \n",
        "\n",
        "Mention: The variables included in the models were selected after following experiments and the current form was selected because it offered the highest R2 coefficient values for model prediction. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Potential improvements\n",
        "- The main area for improvement remains outliers, looking for other solutions to deal with them could help to normalize the distributions and create better regression models.\n",
        "- Another improvement may be to reduce the categories for some variables so that they can be recoded more easily into fewer categories"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
